// Preset simulation configurations for common use cases
export const PRESETS = {
  quickstart: {
    name: 'Quick Start',
    subtitle: '5 rounds / 5 clients',
    description:
      'Fast baseline to verify setup. Perfect first simulation for students learning federated learning.',
    estimatedTime: '20-40 seconds',
    icon: 'üöÄ',
    config: {
      num_of_rounds: 5,
      num_of_clients: 5,
      num_of_malicious_clients: 0,
      aggregation_strategy_keyword: 'fedavg',
      min_fit_clients: 5,
      min_evaluate_clients: 5,
      min_available_clients: 5,
      dataset_source: 'local',
      dataset_keyword: 'femnist_iid',
      remove_clients: 'false',
      begin_removing_from_round: 1,
    },
  },
  quick_sentiment: {
    name: 'DistilBERT Quick Test',
    subtitle: '5 rounds / 3 clients (1 malicious) (~4-6 minutes)',
    description:
      'Fast transformer demo with adversarial learning. Watch federated sentiment analysis handle a poisoning attack! Uses aggressive training for dramatic accuracy improvements.',
    estimatedTime: '4-6 minutes',
    icon: '‚ö°',
    tags: ['cpu-only', 'educational'],
    warningNote: 'First-time run includes model download overhead. Subsequent runs are faster.',
    config: {
      num_of_rounds: 5,
      num_of_clients: 3,
      num_of_malicious_clients: 1,
      aggregation_strategy_keyword: 'fedavg',
      min_fit_clients: 3,
      min_evaluate_clients: 3,
      min_available_clients: 3,
      dataset_source: 'huggingface',
      dataset_keyword: null, // Explicitly null for HuggingFace datasets
      hf_dataset_name: 'stanfordnlp/sst2',
      partitioning_strategy: 'iid',
      model_type: 'transformer',
      transformer_model: 'distilbert-base-uncased',
      max_seq_length: 64,
      text_column: 'sentence',
      label_column: 'label',
      use_lora: true,
      lora_rank: 4,
      batch_size: 8,
      num_of_client_epochs: 3,
      training_subset_fraction: 0.005,
      training_device: 'cuda',
      remove_clients: 'false',
      begin_removing_from_round: 1,
      attack_type: 'gaussian_noise',
      attack_ratio: 1.0,
      gaussian_noise_mean: 0,
      gaussian_noise_std: 50,
    },
  },
  convergence: {
    name: 'Non-IID Challenge',
    subtitle: '15 rounds / 8 clients (Heterogeneous)',
    description:
      'Non-IID data distribution with PID defense. Shows how heterogeneous client data affects convergence and triggers adaptive removal.',
    estimatedTime: '60-90 seconds',
    icon: 'üìä',
    config: {
      num_of_rounds: 15,
      num_of_clients: 8,
      num_of_malicious_clients: 0,
      aggregation_strategy_keyword: 'pid',
      min_fit_clients: 8,
      min_evaluate_clients: 8,
      min_available_clients: 8,
      dataset_source: 'local',
      dataset_keyword: 'femnist_non_iid',
      remove_clients: 'true',
      begin_removing_from_round: 2,
    },
  },
  byzantine: {
    name: 'Byzantine Attack',
    subtitle: '10 clients (3 malicious) + Krum',
    description:
      'Demonstrates Krum defense against 3 malicious clients performing label flipping attacks in rounds 3-8. Watch Byzantine-robust aggregation filter out bad updates!',
    estimatedTime: '90-120 seconds',
    icon: '‚öîÔ∏è',
    config: {
      num_of_rounds: 12,
      num_of_clients: 10,
      num_of_malicious_clients: 3,
      aggregation_strategy_keyword: 'krum',
      num_krum_selections: 6,
      min_fit_clients: 10,
      min_evaluate_clients: 10,
      min_available_clients: 10,
      dataset_source: 'local',
      dataset_keyword: 'femnist_iid',
      remove_clients: 'true',
      begin_removing_from_round: 2,
      dynamic_attacks: {
        enabled: true,
        schedule: [
          {
            start_round: 3,
            end_round: 8,
            selection_strategy: 'specific',
            client_ids: [0, 1, 2],
            attack_config: {
              type: 'label_flipping',
              params: { flip_fraction: 0.7, num_classes: 62 },
            },
          },
        ],
      },
    },
  },
  medical: {
    name: 'Federated Handwriting',
    subtitle: 'HuggingFace FEMNIST + Dirichlet (Œ±=0.3)',
    description:
      'Handwriting recognition with Dirichlet data heterogeneity (Œ±=0.3) using HuggingFace FEMNIST. Trimmed Mean aggregation provides robustness against outliers.',
    estimatedTime: '2-3 minutes',
    icon: '‚úçÔ∏è',
    config: {
      num_of_rounds: 10,
      num_of_clients: 8,
      num_of_malicious_clients: 0,
      aggregation_strategy_keyword: 'trimmed_mean',
      trim_ratio: 0.2,
      min_fit_clients: 8,
      min_evaluate_clients: 8,
      min_available_clients: 8,
      dataset_source: 'huggingface',
      hf_dataset_name: 'flwrlabs/femnist',
      partitioning_strategy: 'dirichlet',
      partitioning_params: { alpha: 0.3 },
      model_type: 'cnn',
      label_column: 'character',
      batch_size: 32,
      remove_clients: 'true',
      begin_removing_from_round: 2,
    },
  },
  sentiment: {
    name: 'Sentiment Analysis',
    subtitle: 'SST-2 + DistilBERT',
    description:
      'Movie review sentiment classification with Dirichlet partitioning. Showcases transformer models with LoRA for efficient training.',
    estimatedTime: '2-3 minutes',
    icon: 'üí¨',
    config: {
      num_of_rounds: 10,
      num_of_clients: 8,
      num_of_malicious_clients: 0,
      aggregation_strategy_keyword: 'fedavg',
      min_fit_clients: 8,
      min_evaluate_clients: 8,
      min_available_clients: 8,
      dataset_source: 'huggingface',
      hf_dataset_name: 'stanfordnlp/sst2',
      partitioning_strategy: 'dirichlet',
      partitioning_params: { alpha: 0.5 },
      model_type: 'transformer',
      transformer_model: 'distilbert-base-uncased',
      max_seq_length: 128,
      text_column: 'sentence',
      label_column: 'label',
      use_lora: true,
      lora_rank: 8,
      batch_size: 16,
      num_of_client_epochs: 1,
      remove_clients: 'false',
      begin_removing_from_round: 1,
    },
  },
  adaptive_defense: {
    name: 'Adaptive Defense Showcase',
    subtitle: '20 rounds / 12 clients (Multi-phase)',
    description:
      'Advanced simulation with dynamic poisoning attacks across 3 phases (label flip ‚Üí noise ‚Üí heavy flip). PID defense adapts and removes compromised clients in real-time.',
    estimatedTime: '2-3 minutes',
    icon: 'üõ°Ô∏è',
    config: {
      num_of_rounds: 20,
      num_of_clients: 12,
      num_of_malicious_clients: 0,
      aggregation_strategy_keyword: 'pid',
      min_fit_clients: 12,
      min_evaluate_clients: 12,
      min_available_clients: 12,
      dataset_source: 'local',
      dataset_keyword: 'femnist_iid',
      remove_clients: 'true',
      begin_removing_from_round: 2,
      Kp: 1.0,
      Ki: 0.05,
      Kd: 0.05,
      num_std_dev: 2.0,
      dynamic_attacks: {
        enabled: true,
        schedule: [
          {
            start_round: 3,
            end_round: 7,
            selection_strategy: 'specific',
            client_ids: [0, 1],
            attack_config: {
              type: 'label_flipping',
              params: { flip_fraction: 0.3, num_classes: 62 },
            },
          },
          {
            start_round: 8,
            end_round: 14,
            selection_strategy: 'specific',
            client_ids: [0, 1, 2, 3],
            attack_config: {
              type: 'gaussian_noise',
              params: { mean: 0, std: 50 },
            },
          },
          {
            start_round: 15,
            end_round: 20,
            selection_strategy: 'specific',
            client_ids: [4, 5, 6],
            attack_config: {
              type: 'label_flipping',
              params: { flip_fraction: 0.8, num_classes: 62 },
            },
          },
        ],
      },
    },
  },
  gpu_optimized: {
    name: 'GPU Performance Demo',
    subtitle: '5 rounds / 5 clients (GPU Optimized)',
    description:
      'Demonstrates optimal GPU utilization with parallel client execution (5 clients √ó 0.2 GPU = full GPU usage). LoRA-enhanced DistilBERT on SST-2 sentiment analysis. Automatically falls back to CPU if GPU unavailable.',
    estimatedTime: '3-5 minutes (GPU) / 8-12 minutes (CPU)',
    icon: '‚ö°',
    tags: ['gpu-recommended', 'performance'],
    warningNote:
      'Optimized for GPUs with 6GB+ VRAM (e.g., RTX 3060). Automatic CPU fallback with performance warning if GPU unavailable.',
    config: {
      num_of_rounds: 5,
      num_of_clients: 5,
      num_of_malicious_clients: 0,
      aggregation_strategy_keyword: 'fedavg',
      min_fit_clients: 5,
      min_evaluate_clients: 5,
      min_available_clients: 5,
      evaluate_metrics_aggregation_fn: 'weighted_average',
      dataset_source: 'huggingface',
      dataset_keyword: null,
      hf_dataset_name: 'stanfordnlp/sst2',
      partitioning_strategy: 'iid',
      partitioning_params: {},
      training_subset_fraction: 0.1,
      model_type: 'transformer',
      transformer_model: 'distilbert-base-uncased',
      max_seq_length: 128,
      text_column: 'sentence',
      label_column: 'label',
      use_lora: true,
      lora_rank: 8,
      batch_size: 32,
      num_of_client_epochs: 3,
      training_device: 'cuda',
      cpus_per_client: 2,
      gpus_per_client: 0.2,
      remove_clients: 'false',
      begin_removing_from_round: 1,
      show_plots: 'false',
      save_plots: 'true',
      save_csv: 'true',
      preserve_dataset: 'true',
    },
  },
};
